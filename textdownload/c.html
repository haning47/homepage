import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from google.colab import files
import time
import os
import re

# -----------------
# 1. 讓使用者輸入目標網址
# -----------------
print("----------------------------------------")
print("歡迎使用檔案下載工具！")
print("----------------------------------------")

# 使用 input() 讓使用者在 Colab 儲存格下方輸入網址
base_url = input("請輸入您想要下載檔案的網頁完整 URL (網址)：")

if not base_url:
    print("錯誤：未輸入網址。程式終止。")
    exit()

# 確保網址格式正確
if not base_url.startswith('http'):
    base_url = 'https://' + base_url

# 定義要下載的常見檔案副檔名
FILE_EXTENSIONS = ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip', '.rar', '.7z']

# 儲存 (檔名, 連結) 的字典
download_items = {} 

print(f"開始掃描網頁：{base_url}")

# -----------------
# 2. 爬取網頁內容並解析連結和文字
# -----------------
try:
    # 設置標頭模擬瀏覽器
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(base_url, headers=headers, timeout=15)
    response.raise_for_status() # 檢查 HTTP 請求是否成功
except requests.exceptions.RequestException as e:
    print(f"無法取得網頁內容，請檢查網址或網路連線。錯誤：{e}")
    exit()

soup = BeautifulSoup(response.text, 'html.parser')

# 尋找所有超連結
all_links = soup.find_all('a', href=True)

# 定義一個函數來清理檔名，移除非法字元
def sanitize_filename(text):
    # 移除 Windows/Linux 不允許的字元
    cleaned = re.sub(r'[\\/:*?"<>|]', '_', text)
    # 移除開頭或結尾的空白
    return cleaned.strip()

for link in all_links:
    href = link['href']
    link_text = link.get_text(strip=True) # 獲取超連結的文字內容

    # 檢查連結是否指向特定的檔案類型
    for ext in FILE_EXTENSIONS:
        if href.lower().endswith(ext):
            absolute_url = urljoin(base_url, href)
            
            # A. 取得副檔名
            file_extension = ext
            
            # B. 建立新檔名：清理後的連結文字 + 副檔名
            base_name = sanitize_filename(link_text)
            
            # 如果連結文字太短或不適合，可以使用 URL 中提取的檔名作為備用
            if not base_name or len(base_name) < 3:
                 url_filename = absolute_url.split('/')[-1].split('?')[0]
                 base_name = sanitize_filename(os.path.splitext(url_filename)[0])
                 
            new_filename = f"{base_name}{file_extension}"

            # 確保檔名是唯一的 (如果有多個連結文字相同的檔案)
            count = 1
            final_filename = new_filename
            while final_filename in download_items:
                final_filename = f"{base_name}_{count}{file_extension}"
                count += 1
                
            download_items[final_filename] = absolute_url
            break

# -----------------
# 3. 下載檔案到 Colab 並傳輸到本地端
# -----------------

if not download_items:
    print("在此網頁中沒有找到可供下載的常見檔案連結。")
else:
    total_files = len(download_items)
    print(f"----------------------------------------")
    print(f"總共找到 {total_files} 個檔案連結，開始下載...")
    print(f"----------------------------------------")

    for i, (filename, file_url) in enumerate(download_items.items()):
        
        print(f"\n[{i+1}/{total_files}] 檔案名稱：{filename}")
        print(f"   -> 原始連結：{file_url}")
        
        try:
            # A. 下載檔案到 Colab 暫存空間
            file_response = requests.get(file_url, stream=True, timeout=30, headers=headers)
            file_response.raise_for_status()

            print(f"   -> 下載中... (大小: {len(file_response.content) / 1024:.2f} KB)")
            with open(filename, 'wb') as f:
                f.write(file_response.content) 

            # B. 透過瀏覽器將檔案傳輸到您的本地電腦
            print(f"   -> 傳輸到本地電腦的預設下載資料夾...")
            files.download(filename)
            
            # 由於瀏覽器需要時間處理下載，延遲 2 秒確保下載指令送出
            time.sleep(2) 
            
        except Exception as e:
            print(f"   -> 下載或傳輸 {filename} 時發生錯誤: {e}")

    print("\n========================================")
    print("🎉 所有檔案下載程序已發送完成！")
    print("請檢查您的瀏覽器下載佇列或本地電腦的預設下載資料夾。")
    print("========================================")